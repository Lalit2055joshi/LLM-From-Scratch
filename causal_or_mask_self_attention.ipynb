{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b596896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9eaf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.w_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.w_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.w_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.w_key\n",
    "        queries = x @ self.w_query\n",
    "        values = x @ self.w_value\n",
    "\n",
    "        d_k = keys.shape[-1]\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.nn.functional.softmax(attn_scores / torch.sqrt(torch.tensor(d_k)), dim=-1)\n",
    "        context_vector = attn_weights @ values\n",
    "        return context_vector, attn_weights, attn_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "543ce98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[0.72, 0.45, 0.310], #Dream\n",
    "    [0.75, 0.20,0.55], #big\n",
    "    [0.30,0.80,0.40], #and\n",
    "    [0.85,0.35,0.60], #work\n",
    "    [0.55,0.15,0.75], #for\n",
    "    [0.25,0.20,0.85] #it\n",
    "    ]\n",
    ")\n",
    "\n",
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out =2\n",
    "\n",
    "#corresponding wordss\n",
    "words = [\"Dream\", \"big\", \"and\", \"work\", \"for\", \"it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a5eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "atten_obj = SelfAttention(d_in, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ee212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector, attention_weights, attn_scores = atten_obj.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e3d856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1581, 0.1610, 0.1710, 0.1981, 0.1609, 0.1510],\n",
       "        [0.1577, 0.1609, 0.1707, 0.1987, 0.1610, 0.1510],\n",
       "        [0.1566, 0.1613, 0.1691, 0.1982, 0.1622, 0.1526],\n",
       "        [0.1557, 0.1597, 0.1713, 0.2055, 0.1598, 0.1480],\n",
       "        [0.1572, 0.1613, 0.1695, 0.1974, 0.1620, 0.1525],\n",
       "        [0.1573, 0.1621, 0.1680, 0.1939, 0.1634, 0.1552]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c843711",
   "metadata": {},
   "source": [
    "#### Lower triangular matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10651ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0] # or you can simply do inputs.shape[0]\n",
    "mask_sample = torch.tril(torch.ones((context_length, context_length)))\n",
    "mask_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6602a",
   "metadata": {},
   "source": [
    "#### Attention weights after applying mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580f10b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1467, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1485, 0.1725, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1412, 0.1741, 0.1270, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1438, 0.1738, 0.1303, 0.1962, 0.0000, 0.0000],\n",
       "        [0.1484, 0.1724, 0.1376, 0.1894, 0.1807, 0.0000],\n",
       "        [0.1483, 0.1721, 0.1379, 0.1889, 0.1808, 0.1720]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sample = attention_weights * mask_sample\n",
    "masked_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc1938",
   "metadata": {},
   "source": [
    "#### Attention weights normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd0b5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4626, 0.5374, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3192, 0.3937, 0.2871, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2233, 0.2698, 0.2023, 0.3046, 0.0000, 0.0000],\n",
       "        [0.1791, 0.2080, 0.1661, 0.2286, 0.2181, 0.0000],\n",
       "        [0.1483, 0.1721, 0.1379, 0.1889, 0.1808, 0.1720]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_sum = masked_sample.sum(dim=1, keepdim=True)\n",
    "masked_simple_normalized = masked_sample / rows_sum\n",
    "masked_simple_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4e10b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1467],\n",
       "        [0.3211],\n",
       "        [0.4423],\n",
       "        [0.6440],\n",
       "        [0.8286],\n",
       "        [1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af143b0",
   "metadata": {},
   "source": [
    "#### Here what actually we do for mask self attention\n",
    "![image](./images/masked_self_attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a25bc0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31e5c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6464,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.5821, 0.7318,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.8037, 1.0133, 0.6976,   -inf,   -inf,   -inf],\n",
       "        [0.7351, 0.9243, 0.6364, 1.0457,   -inf,   -inf],\n",
       "        [0.5728, 0.7222, 0.4972, 0.8168, 0.7696,   -inf],\n",
       "        [0.5621, 0.7111, 0.4895, 0.8038, 0.7600, 0.7100]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = attn_scores / torch.sqrt(torch.tensor(d_out))\n",
    "masked = attention_scores.masked_fill(mask == 1, float('-inf'))\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06067347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4626, 0.5374, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3192, 0.3937, 0.2871, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2233, 0.2698, 0.2023, 0.3046, 0.0000, 0.0000],\n",
       "        [0.1791, 0.2080, 0.1661, 0.2286, 0.2181, 0.0000],\n",
       "        [0.1483, 0.1721, 0.1379, 0.1889, 0.1808, 0.1720]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_weights = torch.nn.functional.softmax(masked, dim=-1)\n",
    "atten_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7b091",
   "metadata": {},
   "source": [
    "#### Here is how the dropout is implemented in self attention\n",
    "![img](./images/drop_out.png)\n",
    "![img2](./images/dropout_3.png)\n",
    "![img3](./images/dropout_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f09222d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once matrix\n",
    "example = torch.ones(context_length,context_length)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4289a389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 0., 0., 0., 2.],\n",
       "        [0., 0., 2., 2., 0., 0.],\n",
       "        [0., 0., 2., 2., 2., 2.],\n",
       "        [0., 2., 2., 2., 2., 2.],\n",
       "        [2., 0., 0., 2., 0., 0.],\n",
       "        [2., 0., 0., 2., 2., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random dropout with 50% probability\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "dropout(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "002cbb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0747, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7873, 0.5742, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3583, 0.4160, 0.3322, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3443, 0.0000, 0.3778, 0.3615, 0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention weights after dropout mask\n",
    "torch.manual_seed(0)\n",
    "dropout(atten_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee85048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_from_screatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
